{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import copy\n",
    "from DataAugment import data_augment\n",
    "import threading\n",
    "import itertools\n",
    "import math\n",
    "from keras.layers import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(box1,box2):     #box shape like [x1,y1,x2,y2]\n",
    "    x1=max(box1[0],box2[0])\n",
    "    y1=max(box1[1],box2[1])\n",
    "    x2=min(box1[2],box2[2])\n",
    "    y2=min(box1[3],box2[3])\n",
    "    intersection_area=abs((x1-x2)*(y1-y2))\n",
    "    box1_area = abs((box1[2] - box1[0]) * (box1[3] - box1[1]))\n",
    "    box2_area = abs((box2[2] - box2[0]) * (box2[3] - box2[1]))\n",
    "    union_area = box1_area + box2_area - intersection_area\n",
    "    iou =intersection_area / (union_area+1e-6)\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_img_size(width, height, img_min_side=600):\n",
    "    if width <= height:\n",
    "        k = float(img_min_side) / width\n",
    "        resized_height = int(k * height)\n",
    "        resized_width = img_min_side\n",
    "    else:\n",
    "        k = float(img_min_side) / height\n",
    "        resized_width = int(k * width)\n",
    "        resized_height = img_min_side\n",
    "\n",
    "    return resized_width, resized_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pretrained_model import pretrained_resnet\n",
    "def base_layer(inp):\n",
    "    #inp = Input(shape = (None,None,3))\n",
    "    base_network = pretrained_resnet(inp)\n",
    "    base_out = base_network.layers[-1].output\n",
    "    return base_out\n",
    "#i_inp = Input(shape = (None,None,3))\n",
    "#roi_inp = Input(shape = (None,4))\n",
    "#s_layers = base_layer(i_inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def rpn(img_data,w,h,resized_w,resized_h,img_length_calc_function):\n",
    "def rpn(img_data,w,h,resized_w,resized_h):\n",
    "    downscale=float(16)\n",
    "    anc_sizes=[128, 256, 512]\n",
    "    anc_ratios=[[1, 1], [1./math.sqrt(2), 2./math.sqrt(2)], [2./math.sqrt(2), 1./math.sqrt(2)]]\n",
    "    num_anc=9\n",
    "    #(out_w, out_h) = img_length_calc_function(resized_w, resized_h)\n",
    "    i_inp = Input(shape = (resized_h,resized_w,3))\n",
    "    base_out= base_layer(i_inp)\n",
    "    out_w,out_h=base_out.shape[2],base_out.shape[1]\n",
    "    num_ratios=3\n",
    "    y_rpn_overlap=np.zeros((out_h,out_w,num_anc))\n",
    "    y_is_box_valid=np.zeros((out_h,out_w,num_anc))\n",
    "    y_rpn_regr=np.zeros((out_h,out_w,4*num_anc))\n",
    "    num_bbox=len(img_data['bboxes'])\n",
    "    num_anc_for_bbox = np.zeros((num_bbox)).astype(int)\n",
    "    best_anc_for_bbox = -1*np.ones((num_bbox, 4)).astype(int)\n",
    "    best_iou_for_bbox = np.zeros((num_bbox)).astype(np.float32)\n",
    "    best_x_for_bbox = np.zeros((num_bbox, 4)).astype(int)\n",
    "    best_dx_for_bbox = np.zeros((num_bbox, 4)).astype(np.float32)\n",
    "    gtc=np.zeros((num_bbox,4))\n",
    "    for b_num,bbox in enumerate(img_data['bboxes']):\n",
    "        gtc[b_num,0]=bbox['x1']*resized_w/w\n",
    "        gtc[b_num,1]=bbox['x2']*resized_w/w\n",
    "        gtc[b_num,2]=bbox['y1']*resized_h/h\n",
    "        gtc[b_num,3]=bbox['y2']*resized_h/h\n",
    "    for anc_s in range(3):\n",
    "        for anc_r in range(3):\n",
    "            anc_w=anc_sizes[anc_s]*anc_ratios[anc_r][0]\n",
    "            anc_h=anc_sizes[anc_s]*anc_ratios[anc_r][1]\n",
    "            for i in range(out_w):\n",
    "                x1_anc = downscale * (i + 0.5) - anc_w / 2\n",
    "                x2_anc = downscale * (i + 0.5) + anc_w / 2\n",
    "                if x1_anc<0 or x2_anc>resized_w:\n",
    "                    continue\n",
    "                for j in range(out_h):\n",
    "                    y1_anc=downscale*(j+0.5)-anc_h/2\n",
    "                    y2_anc=downscale*(j+0.5)+anc_h/2\n",
    "                    if y1_anc<0 or y2_anc>resized_h:\n",
    "                        continue\n",
    "                    best_iou_for_pos=0.0\n",
    "                    bbox_type='neg'\n",
    "                    for bbox in range(num_bbox):\n",
    "                        k=img_data['bboxes'][bbox]['class']\n",
    "                        now_iou=iou([x1_anc,y1_anc,x2_anc,y2_anc],[gtc[b_num,0],gtc[b_num,2],gtc[b_num,1],gtc[b_num,3]])\n",
    "                        if now_iou>best_iou_for_bbox[bbox] or now_iou>0.7:\n",
    "                            cx=(gtc[b_num,0]+gtc[b_num,1])/2\n",
    "                            cy=(gtc[b_num,2]+gtc[b_num,3])/2\n",
    "                            cxa=x1_anc+x2_anc/2\n",
    "                            cya=y1_anc+y2_anc/2\n",
    "                            tx=(cx-cxa)/x2_anc-x1_anc\n",
    "                            ty=(cy-cya)/y2_anc-y1_anc\n",
    "                            tw=np.log((gtc[b_num,1]-gtc[b_num,0])/(x2_anc-x1_anc))\n",
    "                            th=np.log((gtc[b_num,3]-gtc[b_num,2])/(y2_anc-y1_anc))\n",
    "                        if(k!='bg'):\n",
    "                            if now_iou>best_iou_for_bbox[bbox]:\n",
    "                                best_iou_for_bbox[bbox]=now_iou\n",
    "                                best_anc_for_bbox[bbox]=[j,i,anc_r,anc_s]\n",
    "                                best_x_for_bbox[bbox]=[x1_anc,x2_anc,y1_anc,y2_anc]\n",
    "                                best_dx_for_bbox[bbox]=[tx,ty,tw,th]\n",
    "                            if now_iou>0.7:\n",
    "                                bbox_type='pos'\n",
    "                                num_anc_for_bbox[bbox]+=1\n",
    "                                if now_iou>best_iou_for_pos:\n",
    "                                    best_iou_for_pos=now_iou\n",
    "                                    best_regr=[tx,ty,tw,th]\n",
    "                            if 0.3<now_iou<0.7:\n",
    "                                if bbox_type!='pos':\n",
    "                                    bbox_type='neutral'\n",
    "                    if bbox_type=='neg':\n",
    "                        y_is_box_valid[j,i,anc_r+num_ratios*anc_s]=1\n",
    "                        y_rpn_overlap[j,i,anc_r+num_ratios*anc_s]=0\n",
    "                    elif bbox_type=='neutral':\n",
    "                        y_is_box_valid[j,i,anc_r+num_ratios*anc_s]=0\n",
    "                        y_rpn_overlap[j,i,anc_r+num_ratios*anc_s]=0\n",
    "                    elif bbox_type=='pos':\n",
    "                        y_is_box_valid[j,i,anc_r+num_ratios*anc_s]=1\n",
    "                        y_rpn_overlap[j,i,anc_r+num_ratios*anc_s]=1\n",
    "                        initial = 4 * (anc_r + num_ratios * anc_s)\n",
    "                        y_rpn_regr[j, i, initial:initial+4] = best_regr\n",
    "    \n",
    "    for l in range(num_anc_for_bbox.shape[0]):\n",
    "        if num_anc_for_bbox[l]==0:\n",
    "            if best_anc_for_bbox[l,0]==-1:\n",
    "                continue\n",
    "            y_is_box_valid[best_anc_for_bbox[l,0], best_anc_for_bbox[l,1], best_anc_for_bbox[l,2] + num_ratios *best_anc_for_bbox[l,3]] = 1\n",
    "            y_rpn_overlap[best_anc_for_bbox[l,0], best_anc_for_bbox[l,1], best_anc_for_bbox[l,2] + num_ratios *best_anc_for_bbox[l,3]] = 1                        \n",
    "            initial = 4 * (best_anc_for_bbox[l,2] + num_ratios * best_anc_for_bbox[l,3])\n",
    "            y_rpn_regr[best_anc_for_bbox[l,0], best_anc_for_bbox[l,1], initial:initial+4] = best_dx_for_bbox[l, :]\n",
    "                    \n",
    "    y_rpn_overlap=np.expand_dims(np.transpose(y_rpn_overlap,(2,0,1)),axis=0)\n",
    "    y_is_box_valid=np.expand_dims(np.transpose(y_is_box_valid,(2,0,1)),axis=0)\n",
    "    y_rpn_regr=np.expand_dims(np.transpose(y_rpn_regr,(2,0,1)),axis=0)\n",
    "    \n",
    "    \n",
    "    #pos_site=np.where(np.logical_and(y_rpn_overlap[0,:,:,:](np.equal(y_rpn_overlap[0,:,:,:],1)),y_is_box_valid[0,:,:,:](np.equal(y_is_box_valid[0,:,:,:],1))))\n",
    "    #neg_site=np.where(np.logical_and(y_rpn_overlap[0,:,:,:](np.equal(y_rpn_overlap[0,:,:,:],0)),y_is_box_valid[0,:,:,:](np.equal(y_is_box_valid[0,:,:,:],1))))\n",
    "    pos_site = np.where(np.logical_and(y_rpn_overlap[0, :, :, :] == 1, y_is_box_valid[0, :, :, :] == 1))\n",
    "    neg_site = np.where(np.logical_and(y_rpn_overlap[0, :, :, :] == 0, y_is_box_valid[0, :, :, :] == 1))\n",
    "    \n",
    "    if(len(pos_site[0])>128):\n",
    "        invalid=random.sample(range(len(pos_site[0])),len(pos_site[0])-128)\n",
    "        y_is_box_valid[0, pos_site[0][invalid], pos_site[1][invalid], pos_site[2][invalid]] = 0\n",
    "    if len(neg_site[0])>128:\n",
    "        invalid = random.sample(range(len(neg_site[0])), len(neg_site[0]) - 128)\n",
    "        y_is_box_valid[0, neg_site[0][invalid], neg_site[1][invalid], neg_site[2][invalid]] = 0\n",
    "    \n",
    "    y_rpn_cls=np.concatenate([y_is_box_valid,y_rpn_overlap],axis=1)\n",
    "    y_rpn_regr=np.concatenate([np.repeat(y_rpn_overlap, 4, axis=1), y_rpn_regr],axis=1)\n",
    "    \n",
    "    \n",
    "    return np.copy(y_rpn_cls),np.copy(y_rpn_regr)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 2, 18)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ybv=2*np.ones((1,9,3,2))\n",
    "yro=3*np.ones((1,9,3,2))\n",
    "np.shape(np.concatenate([ybv,yro],axis=1))\n",
    "np.shape(np.transpose(np.concatenate([ybv,yro],axis=1),(0,2,3,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def anch_rpn(all_img_data, class_count,img_length_calc_function,mode='train'):\n",
    "def anch_rpn(all_img_data, class_count,mode='train'):\n",
    "    sample_selector = SampleSelector(class_count)\n",
    "    while True:\n",
    "        if mode=='train':\n",
    "            np.random.shuffle(all_img_data)\n",
    "        for img_data in all_img_data:\n",
    "            \n",
    "                if sample_selector.skip_sample_for_balanced_class(img_data):\n",
    "                    continue\n",
    "                if mode=='train':\n",
    "                    img_data_aug,x_img=data_augment(img_data,augment=True)\n",
    "                else:\n",
    "                    img_data_aug,x_img=data_augment(img_data,augment=False)\n",
    "                (w,h)=(img_data_aug['width'],img_data_aug['height'])\n",
    "                (rows,cols,_)=x_img.shape\n",
    "                assert cols==w\n",
    "                assert rows==h\n",
    "                (resized_w,resized_h)=new_img_size(w,h,600)\n",
    "                x_img=cv2.resize(x_img,(resized_w,resized_h),interpolation=cv2.INTER_CUBIC)\n",
    "                #y_rpn_cls, y_rpn_regr =rpn(img_data_aug, w, h, resized_w, resized_h, img_length_calc_function)\n",
    "                y_rpn_cls, y_rpn_regr =rpn(img_data_aug, w, h, resized_w, resized_h)\n",
    "                x_img=x_img[:,:,(2,1,0)].astype(np.float32)\n",
    "                img_channel_mean = [103.939, 116.779, 123.68]\n",
    "                x_img[:,:,0]-=   img_channel_mean[0]\n",
    "                x_img[:,:,1]-=   img_channel_mean[1]\n",
    "                x_img[:,:,2]-=   img_channel_mean[2]\n",
    "                x_img=np.transpose(x_img,(2,0,1))\n",
    "                x_img=np.expand_dims(x_img,axis=0)\n",
    "                y_rpn_regr[:, y_rpn_regr.shape[1]//2:, :, :] *= 4\n",
    "                x_img = np.transpose(x_img, (0, 2, 3, 1))\n",
    "                y_rpn_cls = np.transpose(y_rpn_cls, (0, 2, 3, 1))\n",
    "                y_rpn_regr = np.transpose(y_rpn_regr, (0, 2, 3, 1))\n",
    "                \n",
    "                #yield x_img, [y_rpn_cls, y_rpn_regr], img_data_aug\n",
    "                yield np.copy(x_img), [np.copy(y_rpn_cls), np.copy(y_rpn_regr)], img_data_aug\n",
    "       \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SampleSelector:\n",
    "    def __init__(self, class_count):\n",
    "        self.classes = [b for b in class_count.keys() if class_count[b] > 0]\n",
    "        self.class_cycle = itertools.cycle(self.classes)\n",
    "        self.curr_class = next(self.class_cycle)\n",
    "    def skip_sample_for_balanced_class(self, img_data):\n",
    "        class_in_img = False\n",
    "        for bbox in img_data['bboxes']:\n",
    "            cls_name = bbox['class']\n",
    "            if cls_name == self.curr_class:\n",
    "                class_in_img = True\n",
    "                self.curr_class = next(self.class_cycle)\n",
    "                break\n",
    "        if class_in_img:\n",
    "            return False\n",
    "        else:\n",
    "            return True           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from Dataextract import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_imgs, cls_count, cls_map  =data(r'C:\\Users\\ANSHUL\\Downloads\\VOCdevkit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_imgs[0]\n",
    "#b[0][0].shape\n",
    "#k=np.where(b[0][0][:,:,:]==1)\n",
    "#print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def get_img_output_length(width, height):\n",
    "#    def get_output_length(input_length):\n",
    "#        # zero_pad\n",
    "#        input_length += 6\n",
    "#        # apply 4 strided convolutions\n",
    "#        filter_sizes = [7, 3, 1, 1]\n",
    "#        stride = 2\n",
    "#        for filter_size in filter_sizes:\n",
    "#            input_length = (input_length - filter_size + stride) // stride\n",
    "#        return input_length\n",
    "\n",
    "  #  return get_output_length(width), get_output_length(height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a,b,c=next(anch_rpn(all_imgs, cls_count,mode='train'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import cv2\n",
    "#cv2.imshow('img',a[0])\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
