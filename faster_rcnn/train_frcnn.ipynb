{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from pretrained_model.ipynb\n",
      "importing Jupyter notebook from rpn.ipynb\n",
      "importing Jupyter notebook from classifier.ipynb\n",
      "importing Jupyter notebook from Datagenerators.ipynb\n",
      "importing Jupyter notebook from DataAugment.ipynb\n",
      "importing Jupyter notebook from Dataextract.ipynb\n",
      "importing Jupyter notebook from Finaltruelabels.ipynb\n",
      "importing Jupyter notebook from losses.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "from keras.layers import Input\n",
    "from pretrained_model import pretrained_resnet\n",
    "from rpn import rpn\n",
    "from classifier import classifier\n",
    "from keras.utils import generic_utils\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import pprint\n",
    "import Datagenerators as D\n",
    "from Dataextract import data\n",
    "import Finaltruelabels as F\n",
    "import losses\n",
    "from DataAugment import data_augment\n",
    "from keras import backend as K\n",
    "import math\n",
    "#import all the ipynb files here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rois = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images, classes_count, class_mapping = data(r'C:\\Users\\ANSHUL\\Downloads\\VOCdevkit')#path(simple_label_path)\n",
    "\n",
    "if 'bg' not in classes_count:\n",
    "    classes_count['bg'] = 0\n",
    "    class_mapping['bg'] = len(class_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images per class:\n",
      "{'aeroplane': 1002,\n",
      " 'bg': 0,\n",
      " 'bicycle': 837,\n",
      " 'bird': 1271,\n",
      " 'boat': 1059,\n",
      " 'bottle': 1561,\n",
      " 'bus': 685,\n",
      " 'car': 2492,\n",
      " 'cat': 1277,\n",
      " 'chair': 3056,\n",
      " 'cow': 771,\n",
      " 'diningtable': 800,\n",
      " 'dog': 1598,\n",
      " 'horse': 803,\n",
      " 'motorbike': 801,\n",
      " 'person': 17401,\n",
      " 'pottedplant': 1202,\n",
      " 'sheep': 1084,\n",
      " 'sofa': 841,\n",
      " 'train': 704,\n",
      " 'tvmonitor': 893}\n",
      "Number of classes (including bg) = 21\n",
      "{'person': 0, 'aeroplane': 1, 'tvmonitor': 2, 'train': 3, 'boat': 4, 'dog': 5, 'chair': 6, 'bird': 7, 'bicycle': 8, 'bottle': 9, 'sheep': 10, 'diningtable': 11, 'horse': 12, 'motorbike': 13, 'sofa': 14, 'cow': 15, 'car': 16, 'cat': 17, 'bus': 18, 'pottedplant': 19, 'bg': 20}\n"
     ]
    }
   ],
   "source": [
    "print('Training images per class:')\n",
    "pprint.pprint(classes_count)\n",
    "print('Number of classes (including bg) = {}'.format(len(classes_count)))\n",
    "random.shuffle(all_images)\n",
    "num_imgs = len(all_images)\n",
    "train_imgs = [s for s in all_images if s['imageset'] == 'trainval']\n",
    "print(class_mapping)\n",
    "#val_imgs = [s for s in all_images if s['imageset'] == 'test']  Validation data is not used "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_output_length(width, height):\n",
    "    def get_output_length(input_length):\n",
    "        # zero_pad\n",
    "        input_length += 6\n",
    "        # apply 4 strided convolutions\n",
    "        filter_sizes = [7, 3, 1, 1]\n",
    "        stride = 2\n",
    "        for filter_size in filter_sizes:\n",
    "            input_length = (input_length - filter_size + stride) // stride\n",
    "        return input_length\n",
    "\n",
    "    return get_output_length(width), get_output_length(height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_layer(inp):\n",
    "    #inp = Input(shape = (None,None,3))\n",
    "    base_network = pretrained_resnet(inp)\n",
    "    base_out = base_network.layers[-1].output\n",
    "    return base_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_inp = Input(shape = (None,None,3))\n",
    "roi_inp = Input(shape = (None,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_layers = base_layer(i_inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_gen_train = D.anch_rpn(train_imgs, classes_count, get_img_output_length, mode='train')\n",
    "data_gen_train = D.anch_rpn(train_imgs, classes_count,mode='train')\n",
    "##data_gen_val = data_generators.get_anchor_gt(val_imgs, classes_count, nn.get_img_output_length, mode='val')\n",
    "#Since we do not have any validation data at this point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_frcnn(anchor_num=9):\n",
    "    inp = Input(shape=(None, None, 3))\n",
    "    proposals = Input(shape=(None,3))\n",
    "\n",
    "    base_network = pretrained_resnet(inp)\n",
    "    base_out = base_network.layers[-1].output\n",
    "    \n",
    "    rpn_class_out,rpn_regr_out= rpn(base_out, anchor_num)[0],rpn(base_out, anchor_num)[1]\n",
    "    \n",
    "    #classifier_img = classifier(base_out, proposals, 32,num_classes=21)\n",
    "    \n",
    "    return [rpn_class_out,rpn_regr_out,base_out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Convolution2D\n",
    "def rpn(base_layers, num_anchors):\n",
    "    x = Convolution2D(512, (3, 3), padding='same', activation='relu', kernel_initializer='normal', name='rpn_conv1')(\n",
    "        base_layers)\n",
    "\n",
    "    x_class = Convolution2D(num_anchors, (1, 1), activation='sigmoid', kernel_initializer='uniform',\n",
    "                            name='rpn_out_class')(x)\n",
    "    x_regr = Convolution2D(num_anchors * 4, (1, 1), activation='linear', kernel_initializer='zero',\n",
    "                           name='rpn_out_regress')(x)\n",
    "\n",
    "    return [x_class, x_regr, base_layers]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# anchor box scales\n",
    "anchor_box_scales = [128, 256, 512]\n",
    "# anchor box ratios\n",
    "anchor_box_ratios = [[1, 1], [1, 2], [2, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_anchors = len(anchor_box_scales) * len(anchor_box_ratios)\n",
    "#rpn = train_frcnn(num_anchors)\n",
    "# rpn will carry [x_class, x_regr, base_layers]\n",
    "rpn = rpn(s_layers, num_anchors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = classifier(s_layers, roi_inp, num_rois, num_classes=len(classes_count))\n",
    "# This will return classes and regr after the roi pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"bn5c_branch2b/cond/Merge:0\", shape=(?, ?, ?, 512), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(s_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rpn = Model(i_inp, rpn[:2])\n",
    "model_classifier = Model([i_inp, roi_inp], classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_all = Model([i_inp, roi_inp], rpn[:2] + classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#        print('loading weights from {}'.format(base_net_weights))\n",
    "#        model_rpn.load_weights(model_path, by_name=True)\n",
    "#        model_classifier.load_weights(model_path, by_name=True)\n",
    "#    except Exception as e:\n",
    "#        print(e)\n",
    "#        print('Could not load pretrained model weights. Weights can be found in the keras application folder '\n",
    "#              'https://github.com/fchollet/keras/tree/master/keras/applications)\n",
    "## This snippet load the weights of rpn and classifier\n",
    "## We have to change the location path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(lr=1e-5)\n",
    "opt_classifier = Adam(lr=1e-5)\n",
    "model_rpn.compile(optimizer=opt,\n",
    "                      loss=[losses.rpn_loss_cls(num_anchors), losses.rpn_loss_regr(num_anchors)])\n",
    "model_classifier.compile(optimizer=opt_classifier,\n",
    "                         loss=[losses.class_loss_cls,losses.class_loss_regr(len(classes_count) - 1)],\n",
    "                         metrics=['accuracy'])\n",
    "model_all.compile(optimizer='sgd', \n",
    "                  loss='mae')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_length = 1000\n",
    "num_epochs = 3000\n",
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = np.zeros((epoch_length, 5))\n",
    "rpn_accuracy_rpn_monitor = []\n",
    "rpn_accuracy_for_epoch = []\n",
    "best_loss = np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3000\n",
      "  15/1000 [..............................] - ETA: 20:49:04 - rpn_cls: 8.3311 - rpn_regr: 177.8219 - detector_cls: 2.4211 - detector_regr: 9.6715"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch_num in range(num_epochs):\n",
    "    progbar = generic_utils.Progbar(epoch_length)\n",
    "    print('Epoch {}/{}'.format(epoch_num + 1, num_epochs))\n",
    "    while True:\n",
    "            if len(rpn_accuracy_rpn_monitor) == epoch_length and True:\n",
    "                mean_overlapping_bboxes = float(sum(rpn_accuracy_rpn_monitor)) / len(rpn_accuracy_rpn_monitor)\n",
    "                rpn_accuracy_rpn_monitor = []\n",
    "                print('Average number of overlapping bounding boxes from RPN = {} for {} previous iterations'.format(\n",
    "                            mean_overlapping_bboxes, epoch_length))\n",
    "                if mean_overlapping_bboxes == 0:\n",
    "                    print('RPN is not producing bounding boxes that overlap the ground truth boxes.' \n",
    "                              'Check RPN settings or keep training.')\n",
    "            X, Y, img_data = next(data_gen_train)\n",
    "            #print(np.asarray(Y).shape)\n",
    "            loss_rpn = model_rpn.train_on_batch(X, Y)\n",
    "\n",
    "            P_rpn = model_rpn.predict_on_batch(X)\n",
    "\n",
    "            result = F.apply_rpn(P_rpn[0], P_rpn[1],overlap_thresh=0.7,max_boxes=300)\n",
    "            #print(result.shape)\n",
    "            X2, Y1, Y2, IouS = F.last_iou(result, img_data, class_mapping)\n",
    "            #print(X2.shape)\n",
    "            #print(Y1.shape)\n",
    "            #print(Y2.shape)\n",
    "            if X2 is None:\n",
    "                rpn_accuracy_rpn_monitor.append(0)\n",
    "                rpn_accuracy_for_epoch.append(0)\n",
    "                continue\n",
    "\n",
    "                \n",
    "            neg_samples = np.where(Y1[0, :, -1] == 1)\n",
    "            pos_samples = np.where(Y1[0, :, -1] == 0)\n",
    "\n",
    "            if len(neg_samples) > 0:\n",
    "                neg_samples = neg_samples[0]\n",
    "            else:\n",
    "                neg_samples = []\n",
    "\n",
    "            if len(pos_samples) > 0:\n",
    "                pos_samples = pos_samples[0]\n",
    "            else:\n",
    "                pos_samples = []\n",
    "                \n",
    "                \n",
    "            rpn_accuracy_rpn_monitor.append(len(pos_samples))\n",
    "            rpn_accuracy_for_epoch.append((len(pos_samples)))\n",
    "               \n",
    "            if num_rois > 1:\n",
    "                if len(pos_samples) < num_rois // 2 and len(pos_samples)!=0:\n",
    "                    selected_pos_samples = pos_samples.tolist()\n",
    "                else:\n",
    "                    if(len(pos_samples)!=0):\n",
    "                        selected_pos_samples = np.random.choice(pos_samples, num_rois // 2, replace=False).tolist()\n",
    "                    else:\n",
    "                        selected_pos_samples=[]\n",
    "                        \n",
    "                try:\n",
    "                    selected_neg_samples = np.random.choice(neg_samples, num_rois - len(selected_pos_samples),\n",
    "                                                                replace=False).tolist()\n",
    "                except:\n",
    "                    if(len(neg_samples)!=0):\n",
    "                        selected_neg_samples = np.random.choice(neg_samples, num_rois - len(selected_pos_samples),\n",
    "                                                                replace=True).tolist()\n",
    "                    else:\n",
    "                        selected_neg_samples=[]\n",
    "\n",
    "                samples = selected_pos_samples + selected_neg_samples\n",
    "            else:\n",
    "                    # in the extreme case where num_rois = 1, we pick a random pos or neg sample\n",
    "                selected_pos_samples = pos_samples.tolist()\n",
    "                selected_neg_samples = neg_samples.tolist()\n",
    "                if np.random.randint(0, 2):\n",
    "                    samples = random.choice(neg_samples)\n",
    "                else:\n",
    "                    samples = random.choice(pos_samples)\n",
    "\n",
    "            loss_class = model_classifier.train_on_batch([X, X2[:, samples, :]],\n",
    "                                                             [Y1[:, samples, :], Y2[:, samples, :]])\n",
    "            losses[i, 0] = loss_rpn[1]\n",
    "            losses[i, 1] = loss_rpn[2]\n",
    "            losses[i, 2] = loss_class[1]\n",
    "            losses[i, 3] = loss_class[2]\n",
    "            losses[i, 4] = loss_class[3]\n",
    "                \n",
    "            i += 1\n",
    "                \n",
    "            progbar.update(i,[('rpn_cls', np.mean(losses[:i, 0])), ('rpn_regr', np.mean(losses[:i, 1])),\n",
    "                                ('detector_cls', np.mean(losses[:i, 2])),\n",
    "                                ('detector_regr', np.mean(losses[:i, 3]))])\n",
    "                \n",
    "            if i == epoch_length:\n",
    "                loss_rpn_cls = np.mean(losses[:, 0])\n",
    "                loss_rpn_regr = np.mean(losses[:, 1])\n",
    "                loss_class_cls = np.mean(losses[:, 2])\n",
    "                loss_class_regr = np.mean(losses[:, 3])\n",
    "                class_acc = np.mean(losses[:, 4])\n",
    "                mean_overlapping_bboxes = float(sum(rpn_accuracy_for_epoch)) / len(rpn_accuracy_for_epoch)\n",
    "                rpn_accuracy_for_epoch = []                \n",
    "                    \n",
    "                if True:\n",
    "                    print('Mean number of bounding boxes from RPN overlapping ground truth boxes: {}'.format(\n",
    "                            mean_overlapping_bboxes))\n",
    "                    print('Classifier accuracy for bounding boxes from RPN: {}'.format(class_acc))\n",
    "                    print('Loss RPN classifier: {}'.format(loss_rpn_cls))\n",
    "                    print('Loss RPN regression: {}'.format(loss_rpn_regr))\n",
    "                    print('Loss Detector classifier: {}'.format(loss_class_cls))\n",
    "                    print('Loss Detector regression: {}'.format(loss_class_regr))  \n",
    "                        \n",
    "                        \n",
    "                curr_loss = loss_rpn_cls + loss_rpn_regr + loss_class_cls + loss_class_regr\n",
    "                i = 0\n",
    "                \n",
    "                if curr_loss < best_loss:\n",
    "                    best_loss = curr_loss\n",
    "                    model_all.save_weights(model_path)\n",
    "                \n",
    "                break\n",
    "\n",
    "                # save model\n",
    "                model_all.save_weights(model_path)\n",
    "print('Training complete, exiting.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
